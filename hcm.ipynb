{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 21:16:33,252 : INFO : Checking directories...\n",
      "2020-02-03 21:16:33,254 : INFO : Directories are set.\n"
     ]
    }
   ],
   "source": [
    "from data.data_set_loaders import load_where2buy_it_data_set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from commons.config import LOGS_PATH\n",
    "from pytorch_metric_learning import losses, miners, samplers, trainers, testers\n",
    "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import logging\n",
    "from data.where2buyit_dataset import Where2BuyItDataset\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 21:16:34,334 : INFO : Loading where2buy it data set\n",
      "Parsing files: 100%|██████████| 16352/16352 [00:00<00:00, 451569.37it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load_where2buy_it_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16352</td>\n",
       "      <td>16352</td>\n",
       "      <td>16352</td>\n",
       "      <td>16352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12242</td>\n",
       "      <td>3999</td>\n",
       "      <td>11</td>\n",
       "      <td>16352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>query</td>\n",
       "      <td>w2bt_5101</td>\n",
       "      <td>dresses</td>\n",
       "      <td>/home/cenk/Research/data-sets/where2buyit/phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4111</td>\n",
       "      <td>12</td>\n",
       "      <td>10468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name    product category  \\\n",
       "count   16352      16352    16352   \n",
       "unique  12242       3999       11   \n",
       "top     query  w2bt_5101  dresses   \n",
       "freq     4111         12    10468   \n",
       "\n",
       "                                                     file  \n",
       "count                                               16352  \n",
       "unique                                              16352  \n",
       "top     /home/cenk/Research/data-sets/where2buyit/phot...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query</td>\n",
       "      <td>w2bt_2026</td>\n",
       "      <td>leggings</td>\n",
       "      <td>/home/cenk/Research/data-sets/where2buyit/phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25942</td>\n",
       "      <td>w2bt_2026</td>\n",
       "      <td>leggings</td>\n",
       "      <td>/home/cenk/Research/data-sets/where2buyit/phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25941</td>\n",
       "      <td>w2bt_2026</td>\n",
       "      <td>leggings</td>\n",
       "      <td>/home/cenk/Research/data-sets/where2buyit/phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25940</td>\n",
       "      <td>w2bt_2026</td>\n",
       "      <td>leggings</td>\n",
       "      <td>/home/cenk/Research/data-sets/where2buyit/phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query</td>\n",
       "      <td>w2bt_2199</td>\n",
       "      <td>leggings</td>\n",
       "      <td>/home/cenk/Research/data-sets/where2buyit/phot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    product  category  \\\n",
       "0  query  w2bt_2026  leggings   \n",
       "1  25942  w2bt_2026  leggings   \n",
       "2  25941  w2bt_2026  leggings   \n",
       "3  25940  w2bt_2026  leggings   \n",
       "4  query  w2bt_2199  leggings   \n",
       "\n",
       "                                                file  \n",
       "0  /home/cenk/Research/data-sets/where2buyit/phot...  \n",
       "1  /home/cenk/Research/data-sets/where2buyit/phot...  \n",
       "2  /home/cenk/Research/data-sets/where2buyit/phot...  \n",
       "3  /home/cenk/Research/data-sets/where2buyit/phot...  \n",
       "4  /home/cenk/Research/data-sets/where2buyit/phot...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image transforms\n",
    "train_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.RandomResizedCrop(scale=(0.16, 1), ratio=(0.75, 1.33), size=227),\n",
    "                                    transforms.RandomHorizontalFlip(0.5),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(227),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_train, df_val= train_test_split(df, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Where2BuyItDataset(df_train, train_transform) \n",
    "val_dataset = Where2BuyItDataset(df_val, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 21:16:34,914 : INFO : VERSION 0.9.70\n"
     ]
    }
   ],
   "source": [
    "import pytorch_metric_learning\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info(\"VERSION %s\"%pytorch_metric_learning.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is a basic multilayer perceptron\n",
    "# This code is from https://github.com/KevinMusgrave/powerful_benchmarker\n",
    "class MLP(nn.Module):\n",
    "    # layer_sizes[0] is the dimension of the input\n",
    "    # layer_sizes[-1] is the dimension of the output\n",
    "    def __init__(self, layer_sizes, final_relu=False):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        layer_sizes = [int(x) for x in layer_sizes]\n",
    "        num_layers = len(layer_sizes) - 1\n",
    "        final_relu_layer = num_layers if final_relu else num_layers - 1\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            input_size = layer_sizes[i]\n",
    "            curr_size = layer_sizes[i + 1]\n",
    "            if i < final_relu_layer:\n",
    "                layer_list.append(nn.ReLU(inplace=True))\n",
    "            layer_list.append(nn.Linear(input_size, curr_size))\n",
    "        self.net = nn.Sequential(*layer_list)\n",
    "        self.last_linear = self.net[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# This is for replacing the last layer of a pretrained network.\n",
    "# This code is from https://github.com/KevinMusgrave/powerful_benchmarker\n",
    "class Identity(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# This code is from https://github.com/KevinMusgrave/powerful_benchmarker\n",
    "class ListOfModels(nn.Module):\n",
    "    def __init__(self, list_of_models, input_sizes=None, operation_before_concat=None):\n",
    "        super().__init__()\n",
    "        self.list_of_models = nn.ModuleList(list_of_models)\n",
    "        self.input_sizes = input_sizes\n",
    "        self.operation_before_concat = (lambda x: x) if not operation_before_concat else operation_before_concat\n",
    "        for k in [\"mean\", \"std\", \"input_space\", \"input_range\"]:\n",
    "            setattr(self, k, getattr(list_of_models[0], k, None))\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        if self.input_sizes is None:\n",
    "            for m in self.list_of_models:\n",
    "                curr_output = self.operation_before_concat(m(x))\n",
    "                outputs.append(curr_output)\n",
    "        else:\n",
    "            s = 0\n",
    "            for i, y in enumerate(self.input_sizes):\n",
    "                curr_input = x[:, s : s + y]\n",
    "                curr_output = self.operation_before_concat(self.list_of_models[i](curr_input))\n",
    "                outputs.append(curr_output)\n",
    "                s += y\n",
    "        return torch.cat(outputs, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunk1 = models.shufflenet_v2_x0_5(pretrained=True)\n",
    "trunk2 = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "trunk3 = models.resnet18(pretrained=True)\n",
    "all_trunks = [trunk1, trunk2, trunk3]\n",
    "trunk_output_sizes = []\n",
    "\n",
    "for T in all_trunks:\n",
    "    trunk_output_sizes.append(T.fc.in_features)\n",
    "    T.fc = Identity()\n",
    "\n",
    "trunk = ListOfModels(all_trunks)\n",
    "trunk = torch.nn.DataParallel(trunk.to(device))\n",
    "\n",
    "# Set the embedders. Each embedder takes a corresponding trunk model output, and outputs 64-dim embeddings.\n",
    "all_embedders = []\n",
    "for s in trunk_output_sizes:\n",
    "    all_embedders.append(MLP([s, 64]))\n",
    "\n",
    "# The output of embedder will be of size 64*3.\n",
    "embedder = ListOfModels(all_embedders, input_sizes=trunk_output_sizes)\n",
    "embedder = torch.nn.DataParallel(embedder.to(device))\n",
    "\n",
    "# Set optimizers\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.00001, weight_decay=0.00005)\n",
    "embedder_optimizer = torch.optim.Adam(embedder.parameters(), lr=0.00001, weight_decay=0.00005)\n",
    "\n",
    "# Set the loss functions. loss0 will be applied to the first embedder, loss1 to the second embedder etc.\n",
    "loss0 = losses.TripletMarginLoss(margin=0.01)\n",
    "loss1 = losses.MultiSimilarityLoss(alpha=0.1, beta=40, base=0.5)\n",
    "loss2 = losses.ArcFaceLoss(margin=30, num_classes=100, embedding_size=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1d3420b32697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Set the dataloader sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMPerClassSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Set other training parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/cv/image-retrieval/visual-fashion-item-search/data/where2buyit_dataset.py\u001b[0m in \u001b[0;36mtargets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the mining functions. In this example we'll apply mining to the 2nd and 3rd cascaded outputs.\n",
    "miner1 = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "miner2 = miners.HDCMiner(filter_percentage=0.25)\n",
    "\n",
    "# Set the dataloader sampler\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets(), m=2)\n",
    "\n",
    "# Set other training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 2\n",
    "iterations_per_epoch = 100\n",
    "\n",
    "# Package the above stuff into dictionaries.\n",
    "models = {\"trunk\": trunk, \"embedder\": embedder}\n",
    "optimizers = {\"trunk_optimizer\": trunk_optimizer, \"embedder_optimizer\": embedder_optimizer}\n",
    "loss_funcs = {\"metric_loss_0\": loss0, \"metric_loss_1\": loss1, \"metric_loss_2\": loss2}\n",
    "mining_funcs = {\"post_gradient_miner_1\": miner1, \"post_gradient_miner_2\": miner2}\n",
    "\n",
    "record_keeper, _, _ = logging_presets.get_record_keeper(\"example_logs\", LOGS_PATH)\n",
    "hooks = logging_presets.get_hook_container(record_keeper)\n",
    "dataset_dict = {\"val\": val_dataset}\n",
    "model_folder = \"example_saved_models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tester\n",
    "tester = testers.GlobalEmbeddingSpaceTester(end_of_testing_hook=hooks.end_of_testing_hook)\n",
    "end_of_epoch_hook = hooks.end_of_epoch_hook(tester, dataset_dict, model_folder)\n",
    "trainer = trainers.CascadedEmbeddings(models=models,\n",
    "                                    optimizers=optimizers,\n",
    "                                    batch_size=batch_size,\n",
    "                                    loss_funcs=loss_funcs,\n",
    "                                    mining_funcs=mining_funcs,\n",
    "                                    iterations_per_epoch=iterations_per_epoch,\n",
    "                                    dataset=train_dataset,\n",
    "                                    sampler=sampler,\n",
    "                                    end_of_iteration_hook=hooks.end_of_iteration_hook,\n",
    "                                    end_of_epoch_hook=end_of_epoch_hook,\n",
    "                                    embedding_sizes=[64, 64, 64])\n",
    "\n",
    "trainer.train(num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}